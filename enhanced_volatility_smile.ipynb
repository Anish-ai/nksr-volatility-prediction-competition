{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.interpolate import interp1d, UnivariateSpline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.optimize import minimize\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data Loading and Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (178340, 97)\n",
      "Test shape: (12065, 96)\n",
      "Sample submission shape: (12065, 53)\n",
      "\n",
      "Train data head:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>underlying</th>\n",
       "      <th>expiry</th>\n",
       "      <th>call_iv_23500</th>\n",
       "      <th>call_iv_23600</th>\n",
       "      <th>call_iv_23700</th>\n",
       "      <th>call_iv_23800</th>\n",
       "      <th>call_iv_23900</th>\n",
       "      <th>call_iv_24000</th>\n",
       "      <th>call_iv_24100</th>\n",
       "      <th>...</th>\n",
       "      <th>X32</th>\n",
       "      <th>X33</th>\n",
       "      <th>X34</th>\n",
       "      <th>X35</th>\n",
       "      <th>X36</th>\n",
       "      <th>X37</th>\n",
       "      <th>X38</th>\n",
       "      <th>X39</th>\n",
       "      <th>X40</th>\n",
       "      <th>X41</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1745296089000000000</td>\n",
       "      <td>24160.9</td>\n",
       "      <td>2025-04-24</td>\n",
       "      <td>0.237872</td>\n",
       "      <td>0.213056</td>\n",
       "      <td>0.191247</td>\n",
       "      <td>0.173081</td>\n",
       "      <td>0.157550</td>\n",
       "      <td>0.146430</td>\n",
       "      <td>0.140084</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013995</td>\n",
       "      <td>0.007922</td>\n",
       "      <td>-1.947502e+05</td>\n",
       "      <td>0.024715</td>\n",
       "      <td>0.530894</td>\n",
       "      <td>-0.002354</td>\n",
       "      <td>-3.224848e+05</td>\n",
       "      <td>-1.600795e+06</td>\n",
       "      <td>13063.446970</td>\n",
       "      <td>445511.363636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1745304077000000000</td>\n",
       "      <td>24188.1</td>\n",
       "      <td>2025-04-24</td>\n",
       "      <td>0.236015</td>\n",
       "      <td>0.213177</td>\n",
       "      <td>0.189552</td>\n",
       "      <td>0.169672</td>\n",
       "      <td>0.153648</td>\n",
       "      <td>0.141522</td>\n",
       "      <td>0.134405</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.004976</td>\n",
       "      <td>-0.009555</td>\n",
       "      <td>-1.481909e+06</td>\n",
       "      <td>-0.004020</td>\n",
       "      <td>-1.429919</td>\n",
       "      <td>-0.000843</td>\n",
       "      <td>1.658073e+06</td>\n",
       "      <td>-1.742468e+06</td>\n",
       "      <td>31364.628427</td>\n",
       "      <td>-46123.161765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1745313495000000000</td>\n",
       "      <td>24148.6</td>\n",
       "      <td>2025-04-24</td>\n",
       "      <td>0.225757</td>\n",
       "      <td>0.199469</td>\n",
       "      <td>0.178547</td>\n",
       "      <td>0.156187</td>\n",
       "      <td>0.140276</td>\n",
       "      <td>0.130288</td>\n",
       "      <td>0.124253</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.012869</td>\n",
       "      <td>-0.004012</td>\n",
       "      <td>-1.250688e+06</td>\n",
       "      <td>-0.035342</td>\n",
       "      <td>-0.523109</td>\n",
       "      <td>0.013778</td>\n",
       "      <td>-2.646675e+06</td>\n",
       "      <td>-5.051008e+07</td>\n",
       "      <td>-847564.971737</td>\n",
       "      <td>-225333.881579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1745313499000000000</td>\n",
       "      <td>24147.4</td>\n",
       "      <td>2025-04-24</td>\n",
       "      <td>0.220805</td>\n",
       "      <td>0.195398</td>\n",
       "      <td>0.176247</td>\n",
       "      <td>0.155271</td>\n",
       "      <td>0.139753</td>\n",
       "      <td>0.129641</td>\n",
       "      <td>0.123994</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.006014</td>\n",
       "      <td>0.004207</td>\n",
       "      <td>6.378700e+05</td>\n",
       "      <td>-0.045472</td>\n",
       "      <td>0.741664</td>\n",
       "      <td>0.002590</td>\n",
       "      <td>-1.607321e+06</td>\n",
       "      <td>4.170899e+05</td>\n",
       "      <td>333918.361928</td>\n",
       "      <td>-114960.453869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1745313608000000000</td>\n",
       "      <td>24155.9</td>\n",
       "      <td>2025-04-24</td>\n",
       "      <td>0.220088</td>\n",
       "      <td>0.195815</td>\n",
       "      <td>0.177803</td>\n",
       "      <td>0.156409</td>\n",
       "      <td>0.141458</td>\n",
       "      <td>0.130448</td>\n",
       "      <td>0.124707</td>\n",
       "      <td>...</td>\n",
       "      <td>0.020878</td>\n",
       "      <td>-0.001747</td>\n",
       "      <td>9.592702e+04</td>\n",
       "      <td>0.044814</td>\n",
       "      <td>-0.015472</td>\n",
       "      <td>0.012185</td>\n",
       "      <td>6.820360e+05</td>\n",
       "      <td>4.081106e+06</td>\n",
       "      <td>3309.895833</td>\n",
       "      <td>183946.289063</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 97 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             timestamp  underlying      expiry  call_iv_23500  call_iv_23600  \\\n",
       "0  1745296089000000000     24160.9  2025-04-24       0.237872       0.213056   \n",
       "1  1745304077000000000     24188.1  2025-04-24       0.236015       0.213177   \n",
       "2  1745313495000000000     24148.6  2025-04-24       0.225757       0.199469   \n",
       "3  1745313499000000000     24147.4  2025-04-24       0.220805       0.195398   \n",
       "4  1745313608000000000     24155.9  2025-04-24       0.220088       0.195815   \n",
       "\n",
       "   call_iv_23700  call_iv_23800  call_iv_23900  call_iv_24000  call_iv_24100  \\\n",
       "0       0.191247       0.173081       0.157550       0.146430       0.140084   \n",
       "1       0.189552       0.169672       0.153648       0.141522       0.134405   \n",
       "2       0.178547       0.156187       0.140276       0.130288       0.124253   \n",
       "3       0.176247       0.155271       0.139753       0.129641       0.123994   \n",
       "4       0.177803       0.156409       0.141458       0.130448       0.124707   \n",
       "\n",
       "   ...       X32       X33           X34       X35       X36       X37  \\\n",
       "0  ...  0.013995  0.007922 -1.947502e+05  0.024715  0.530894 -0.002354   \n",
       "1  ... -0.004976 -0.009555 -1.481909e+06 -0.004020 -1.429919 -0.000843   \n",
       "2  ... -0.012869 -0.004012 -1.250688e+06 -0.035342 -0.523109  0.013778   \n",
       "3  ... -0.006014  0.004207  6.378700e+05 -0.045472  0.741664  0.002590   \n",
       "4  ...  0.020878 -0.001747  9.592702e+04  0.044814 -0.015472  0.012185   \n",
       "\n",
       "            X38           X39            X40            X41  \n",
       "0 -3.224848e+05 -1.600795e+06   13063.446970  445511.363636  \n",
       "1  1.658073e+06 -1.742468e+06   31364.628427  -46123.161765  \n",
       "2 -2.646675e+06 -5.051008e+07 -847564.971737 -225333.881579  \n",
       "3 -1.607321e+06  4.170899e+05  333918.361928 -114960.453869  \n",
       "4  6.820360e+05  4.081106e+06    3309.895833  183946.289063  \n",
       "\n",
       "[5 rows x 97 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test data head:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>underlying</th>\n",
       "      <th>call_iv_24000</th>\n",
       "      <th>call_iv_24100</th>\n",
       "      <th>call_iv_24200</th>\n",
       "      <th>call_iv_24300</th>\n",
       "      <th>call_iv_24400</th>\n",
       "      <th>call_iv_24500</th>\n",
       "      <th>call_iv_24600</th>\n",
       "      <th>call_iv_24700</th>\n",
       "      <th>...</th>\n",
       "      <th>X32</th>\n",
       "      <th>X33</th>\n",
       "      <th>X34</th>\n",
       "      <th>X35</th>\n",
       "      <th>X36</th>\n",
       "      <th>X37</th>\n",
       "      <th>X38</th>\n",
       "      <th>X39</th>\n",
       "      <th>X40</th>\n",
       "      <th>X41</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>24735.9</td>\n",
       "      <td>0.280939</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.242149</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.232439</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006587</td>\n",
       "      <td>0.002826</td>\n",
       "      <td>-1.737617e+05</td>\n",
       "      <td>-0.009541</td>\n",
       "      <td>-0.017831</td>\n",
       "      <td>0.000264</td>\n",
       "      <td>2.032521e+06</td>\n",
       "      <td>1.000000e-06</td>\n",
       "      <td>-0.077238</td>\n",
       "      <td>-5.362742e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>24766.7</td>\n",
       "      <td>0.270276</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.258893</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.233548</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005777</td>\n",
       "      <td>0.004588</td>\n",
       "      <td>-3.195086e+05</td>\n",
       "      <td>-0.024106</td>\n",
       "      <td>-0.004696</td>\n",
       "      <td>-0.000158</td>\n",
       "      <td>-4.529075e+06</td>\n",
       "      <td>-1.619022e+06</td>\n",
       "      <td>-0.956928</td>\n",
       "      <td>4.624907e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>24896.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.251731</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.214869</td>\n",
       "      <td>0.20458</td>\n",
       "      <td>0.194604</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000829</td>\n",
       "      <td>-0.034944</td>\n",
       "      <td>1.027525e+06</td>\n",
       "      <td>0.028201</td>\n",
       "      <td>0.032234</td>\n",
       "      <td>0.007687</td>\n",
       "      <td>2.663908e+06</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-0.116264</td>\n",
       "      <td>-2.669766e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>24898.1</td>\n",
       "      <td>0.241888</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.220505</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.198602</td>\n",
       "      <td>0.18619</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009323</td>\n",
       "      <td>-0.022969</td>\n",
       "      <td>-4.720074e+06</td>\n",
       "      <td>-0.001513</td>\n",
       "      <td>0.008704</td>\n",
       "      <td>-0.000206</td>\n",
       "      <td>-7.672936e+06</td>\n",
       "      <td>-1.903406e+06</td>\n",
       "      <td>-2.249208</td>\n",
       "      <td>-1.858254e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>24906.5</td>\n",
       "      <td>0.235328</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.222983</td>\n",
       "      <td>0.214126</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.192603</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018674</td>\n",
       "      <td>-0.007588</td>\n",
       "      <td>-4.051681e+05</td>\n",
       "      <td>-0.136267</td>\n",
       "      <td>0.002425</td>\n",
       "      <td>-0.002200</td>\n",
       "      <td>1.334469e+06</td>\n",
       "      <td>2.548789e+05</td>\n",
       "      <td>1.999104</td>\n",
       "      <td>3.024212e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 96 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   timestamp  underlying  call_iv_24000  call_iv_24100  call_iv_24200  \\\n",
       "0          0     24735.9       0.280939            NaN            NaN   \n",
       "1          1     24766.7       0.270276            NaN       0.258893   \n",
       "2          2     24896.9            NaN       0.251731            NaN   \n",
       "3          3     24898.1       0.241888            NaN       0.220505   \n",
       "4          4     24906.5       0.235328            NaN       0.222983   \n",
       "\n",
       "   call_iv_24300  call_iv_24400  call_iv_24500  call_iv_24600  call_iv_24700  \\\n",
       "0            NaN       0.242149            NaN       0.232439            NaN   \n",
       "1            NaN            NaN            NaN       0.233548            NaN   \n",
       "2            NaN       0.214869        0.20458       0.194604            NaN   \n",
       "3            NaN       0.198602        0.18619            NaN            NaN   \n",
       "4       0.214126            NaN            NaN       0.192603            NaN   \n",
       "\n",
       "   ...       X32       X33           X34       X35       X36       X37  \\\n",
       "0  ...  0.006587  0.002826 -1.737617e+05 -0.009541 -0.017831  0.000264   \n",
       "1  ...  0.005777  0.004588 -3.195086e+05 -0.024106 -0.004696 -0.000158   \n",
       "2  ...  0.000829 -0.034944  1.027525e+06  0.028201  0.032234  0.007687   \n",
       "3  ... -0.009323 -0.022969 -4.720074e+06 -0.001513  0.008704 -0.000206   \n",
       "4  ... -0.018674 -0.007588 -4.051681e+05 -0.136267  0.002425 -0.002200   \n",
       "\n",
       "            X38           X39       X40           X41  \n",
       "0  2.032521e+06  1.000000e-06 -0.077238 -5.362742e+06  \n",
       "1 -4.529075e+06 -1.619022e+06 -0.956928  4.624907e+06  \n",
       "2  2.663908e+06  0.000000e+00 -0.116264 -2.669766e+06  \n",
       "3 -7.672936e+06 -1.903406e+06 -2.249208 -1.858254e+07  \n",
       "4  1.334469e+06  2.548789e+05  1.999104  3.024212e+06  \n",
       "\n",
       "[5 rows x 96 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load data\n",
    "train = pd.read_parquet('train_data.parquet')\n",
    "test = pd.read_parquet('test_data.parquet')\n",
    "sample_sub = pd.read_csv('sample_submission.csv')\n",
    "\n",
    "# Display shapes\n",
    "print(f\"Train shape: {train.shape}\")\n",
    "print(f\"Test shape: {test.shape}\")\n",
    "print(f\"Sample submission shape: {sample_sub.shape}\")\n",
    "\n",
    "# Display first few rows of train data\n",
    "print(\"\\nTrain data head:\")\n",
    "display(train.head())\n",
    "\n",
    "# Display first few rows of test data\n",
    "print(\"\\nTest data head:\")\n",
    "display(test.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Data Analysis and Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of IV columns: 52\n",
      "First 5 IV columns: ['call_iv_24000', 'call_iv_24100', 'call_iv_24200', 'call_iv_24300', 'call_iv_24400']\n",
      "\n",
      "Strike dictionary sample:\n",
      "{'24000': {'call': 'call_iv_24000', 'put': 'put_iv_24000'}, '24100': {'call': 'call_iv_24100', 'put': 'put_iv_24100'}, '24200': {'call': 'call_iv_24200', 'put': 'put_iv_24200'}}\n"
     ]
    }
   ],
   "source": [
    "# Get all IV columns from TEST data\n",
    "iv_columns = [col for col in test.columns if col.startswith(('call_iv_', 'put_iv_'))]\n",
    "\n",
    "print(f\"Number of IV columns: {len(iv_columns)}\")\n",
    "print(f\"First 5 IV columns: {iv_columns[:5]}\")\n",
    "\n",
    "# Create strike dictionary from TEST columns\n",
    "strike_dict = {}\n",
    "for col in iv_columns:\n",
    "    strike = col.split('_')[-1]\n",
    "    if strike not in strike_dict:\n",
    "        strike_dict[strike] = {'call': None, 'put': None}\n",
    "    \n",
    "    if col.startswith('call_iv_'):\n",
    "        strike_dict[strike]['call'] = col\n",
    "    else:\n",
    "        strike_dict[strike]['put'] = col\n",
    "\n",
    "print(\"\\nStrike dictionary sample:\")\n",
    "print(dict(list(strike_dict.items())[:3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Feature Engineering and Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Global statistics for first 5 IV columns:\n",
      "call_iv_24000: {'mean': np.float64(1.5803173304391611), 'median': np.float64(0.19670149999999997), 'std': np.float64(402.7997710415377), 'q25': np.float64(0.173014), 'q75': np.float64(0.246242), 'skew': np.float64(298.6109287117417), 'kurt': np.float64(89167.4911304059)}\n",
      "call_iv_24100: {'mean': np.float64(0.1952128715991925), 'median': np.float64(0.17405749999999998), 'std': np.float64(0.05609654334987734), 'q25': np.float64(0.16104975), 'q75': np.float64(0.21034750000000002), 'skew': np.float64(2.328600094123866), 'kurt': np.float64(6.4907873326103225)}\n",
      "call_iv_24200: {'mean': np.float64(0.16099717636929461), 'median': np.float64(0.1578795), 'std': np.float64(0.032195505401451385), 'q25': np.float64(0.14302949999999998), 'q75': np.float64(0.168074), 'skew': np.float64(2.354673666779333), 'kurt': np.float64(8.370033133706862)}\n",
      "call_iv_24300: {'mean': np.float64(0.14009934083043626), 'median': np.float64(0.1427675), 'std': np.float64(0.019030190000839768), 'q25': np.float64(0.12657), 'q75': np.float64(0.1544), 'skew': np.float64(-0.12030330507026903), 'kurt': np.float64(-0.4536256769090379)}\n",
      "call_iv_24400: {'mean': np.float64(0.14688345825782215), 'median': np.float64(0.142993), 'std': np.float64(0.04224110651196065), 'q25': np.float64(0.12066874999999999), 'q75': np.float64(0.15499625), 'skew': np.float64(1.902676644458785), 'kurt': np.float64(5.287879626562631)}\n",
      "\n",
      "Underlying statistics for first 3 underlyings:\n",
      "Underlying 24160.9: 42 IV columns with stats\n",
      "Underlying 24188.1: 42 IV columns with stats\n",
      "Underlying 24148.6: 42 IV columns with stats\n"
     ]
    }
   ],
   "source": [
    "def calculate_enhanced_stats(data):\n",
    "    stats = {}\n",
    "    \n",
    "    # Calculate per-column statistics\n",
    "    for col in iv_columns:\n",
    "        if col in data.columns:\n",
    "            values = data[col].dropna()\n",
    "            if len(values) > 0:\n",
    "                stats[col] = {\n",
    "                    'mean': values.mean(),\n",
    "                    'median': values.median(),\n",
    "                    'std': values.std(),\n",
    "                    'q25': values.quantile(0.25),\n",
    "                    'q75': values.quantile(0.75),\n",
    "                    'skew': values.skew(),\n",
    "                    'kurt': values.kurtosis()\n",
    "                }\n",
    "    \n",
    "    # Calculate underlying-based statistics\n",
    "    underlying_stats = {}\n",
    "    for underlying in data['underlying'].unique():\n",
    "        subset = data[data['underlying'] == underlying]\n",
    "        underlying_stats[underlying] = {}\n",
    "        \n",
    "        for col in iv_columns:\n",
    "            if col in subset.columns:\n",
    "                values = subset[col].dropna()\n",
    "                if len(values) > 0:\n",
    "                    underlying_stats[underlying][col] = {\n",
    "                        'mean': values.mean(),\n",
    "                        'std': values.std(),\n",
    "                        'skew': values.skew(),\n",
    "                        'kurt': values.kurtosis()\n",
    "                    }\n",
    "    \n",
    "    return stats, underlying_stats\n",
    "\n",
    "global_stats, underlying_stats = calculate_enhanced_stats(train)\n",
    "overall_mean = np.mean([stats['mean'] for stats in global_stats.values()]) if global_stats else 0.2\n",
    "\n",
    "print(\"\\nGlobal statistics for first 5 IV columns:\")\n",
    "for col in list(global_stats.keys())[:5]:\n",
    "    print(f\"{col}: {global_stats[col]}\")\n",
    "\n",
    "print(\"\\nUnderlying statistics for first 3 underlyings:\")\n",
    "for underlying in list(underlying_stats.keys())[:3]:\n",
    "    print(f\"Underlying {underlying}: {len(underlying_stats[underlying])} IV columns with stats\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Visualization of IV Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'iv_columns' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Plot distribution of a sample call and put IV\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m sample_call \u001b[38;5;241m=\u001b[39m \u001b[43miv_columns\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m      3\u001b[0m sample_put \u001b[38;5;241m=\u001b[39m iv_columns[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(iv_columns) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m iv_columns[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m      5\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m12\u001b[39m, \u001b[38;5;241m6\u001b[39m))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'iv_columns' is not defined"
     ]
    }
   ],
   "source": [
    "# Plot distribution of a sample call and put IV\n",
    "sample_call = iv_columns[0]\n",
    "sample_put = iv_columns[1] if len(iv_columns) > 1 else iv_columns[0]\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.histplot(train[sample_call].dropna(), kde=True)\n",
    "plt.title(f'Distribution of {sample_call}')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.histplot(train[sample_put].dropna(), kde=True)\n",
    "plt.title(f'Distribution of {sample_put}')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Enhanced SVI Model Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_strike_price(strike_str):\n",
    "    try:\n",
    "        return float(strike_str)\n",
    "    except:\n",
    "        return 0.0\n",
    "\n",
    "def calculate_moneyness(strike, underlying):\n",
    "    \"\"\"Calculate moneyness (strike/underlying)\"\"\"\n",
    "    return strike / underlying if underlying > 0 else 1.0\n",
    "\n",
    "def enhanced_svi_parametrization(k, a, b, rho, m, sigma, c, d):\n",
    "    \"\"\"Enhanced SVI parametrization with additional terms for better smile fitting\"\"\"\n",
    "    return a + b * (rho * (k - m) + np.sqrt((k - m)**2 + sigma**2)) + c * np.exp(-d * (k - m)**2)\n",
    "\n",
    "def fit_enhanced_svi_smile(strikes, ivs, underlying):\n",
    "    \"\"\"Fit enhanced SVI model to volatility smile\"\"\"\n",
    "    if len(strikes) < 4:\n",
    "        return None\n",
    "    \n",
    "    # Convert to log-moneyness\n",
    "    log_moneyness = np.log(np.array(strikes) / underlying)\n",
    "    ivs = np.array(ivs)\n",
    "    \n",
    "    # Initial parameter guess\n",
    "    initial_guess = [\n",
    "        np.mean(ivs),  # a\n",
    "        0.1,           # b  \n",
    "        0.0,           # rho\n",
    "        0.0,           # m\n",
    "        0.1,           # sigma\n",
    "        0.01,          # c\n",
    "        0.1            # d\n",
    "    ]\n",
    "    \n",
    "    def objective(params):\n",
    "        a, b, rho, m, sigma, c, d = params\n",
    "        try:\n",
    "            predicted = enhanced_svi_parametrization(log_moneyness, a, b, rho, m, sigma, c, d)\n",
    "            return np.sum((ivs - predicted)**2)\n",
    "        except:\n",
    "            return 1e6\n",
    "    \n",
    "    # Constraints to ensure no-arbitrage\n",
    "    bounds = [\n",
    "        (-1, 1),      # a\n",
    "        (0, 1),       # b\n",
    "        (-1, 1),      # rho\n",
    "        (-1, 1),      # m\n",
    "        (0.01, 1),    # sigma\n",
    "        (0, 0.1),     # c\n",
    "        (0, 1)        # d\n",
    "    ]\n",
    "    \n",
    "    try:\n",
    "        result = minimize(objective, initial_guess, bounds=bounds, method='L-BFGS-B')\n",
    "        if result.success:\n",
    "            return result.x\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    return None\n",
    "\n",
    "# Example SVI fitting visualization\n",
    "sample_row = train.iloc[0]\n",
    "underlying = sample_row['underlying']\n",
    "strikes = []\n",
    "ivs = []\n",
    "\n",
    "for col in iv_columns[:10]:  # Just use first 10 for visualization\n",
    "    if col in sample_row and not pd.isna(sample_row[col]):\n",
    "        strike = extract_strike_price(col.split('_')[-1])\n",
    "        strikes.append(strike)\n",
    "        ivs.append(sample_row[col])\n",
    "\n",
    "if len(strikes) >= 4:\n",
    "    svi_params = fit_enhanced_svi_smile(strikes, ivs, underlying)\n",
    "    \n",
    "    if svi_params is not None:\n",
    "        # Create smooth curve for visualization\n",
    "        test_strikes = np.linspace(min(strikes), max(strikes), 100)\n",
    "        log_moneyness = np.log(test_strikes / underlying)\n",
    "        svi_curve = enhanced_svi_parametrization(log_moneyness, *svi_params)\n",
    "        \n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.scatter(strikes, ivs, color='red', label='Original Data Points')\n",
    "        plt.plot(test_strikes, svi_curve, label='Enhanced SVI Fit')\n",
    "        plt.xlabel('Strike Price')\n",
    "        plt.ylabel('Implied Volatility')\n",
    "        plt.title('Enhanced SVI Volatility Smile Fit')\n",
    "        plt.legend()\n",
    "        plt.grid()\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(\"Could not fit SVI to sample data\")\n",
    "else:\n",
    "    print(\"Not enough data points for SVI fit visualization\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Advanced Interpolation Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def advanced_interpolation(strikes, ivs, target_strikes, method='enhanced_svi'):\n",
    "    \"\"\"Advanced interpolation methods with enhanced SVI\"\"\"\n",
    "    if len(strikes) < 2:\n",
    "        return np.full(len(target_strikes), np.mean(ivs) if ivs else 0.2)\n",
    "    \n",
    "    # Remove duplicates and sort\n",
    "    combined = list(zip(strikes, ivs))\n",
    "    combined = sorted(list(set(combined)))\n",
    "    strikes, ivs = zip(*combined) if combined else (strikes, ivs)\n",
    "    \n",
    "    strikes = np.array(strikes)\n",
    "    ivs = np.array(ivs)\n",
    "    target_strikes = np.array(target_strikes)\n",
    "    \n",
    "    try:\n",
    "        if method == 'enhanced_svi':\n",
    "            # Try enhanced SVI first\n",
    "            svi_params = fit_enhanced_svi_smile(strikes, ivs, np.mean(strikes))\n",
    "            if svi_params is not None:\n",
    "                log_moneyness = np.log(target_strikes / np.mean(strikes))\n",
    "                predicted = enhanced_svi_parametrization(log_moneyness, *svi_params)\n",
    "                return np.clip(predicted, 0.01, 0.99)\n",
    "        \n",
    "        # Fallback to cubic spline\n",
    "        if len(strikes) >= 4:\n",
    "            spline = UnivariateSpline(strikes, ivs, s=len(strikes)*0.01, k=3)\n",
    "            return np.clip(spline(target_strikes), 0.01, 0.99)\n",
    "        \n",
    "        # Fallback to linear interpolation\n",
    "        f = interp1d(strikes, ivs, kind='linear', bounds_error=False, fill_value='extrapolate')\n",
    "        return np.clip(f(target_strikes), 0.01, 0.99)\n",
    "            \n",
    "    except:\n",
    "        # Fallback to mean\n",
    "        return np.full(len(target_strikes), np.mean(ivs))\n",
    "\n",
    "# Compare interpolation methods\n",
    "if len(strikes) >= 4:\n",
    "    test_points = np.linspace(min(strikes), max(strikes), 100)\n",
    "    \n",
    "    # Get interpolations\n",
    "    svi_interp = advanced_interpolation(strikes, ivs, test_points, 'enhanced_svi')\n",
    "    spline_interp = advanced_interpolation(strikes, ivs, test_points, 'spline')\n",
    "    linear_interp = advanced_interpolation(strikes, ivs, test_points, 'linear')\n",
    "    \n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.scatter(strikes, ivs, color='black', label='Original Data', zorder=5)\n",
    "    plt.plot(test_points, svi_interp, label='Enhanced SVI')\n",
    "    plt.plot(test_points, spline_interp, label='Cubic Spline')\n",
    "    plt.plot(test_points, linear_interp, label='Linear')\n",
    "    plt.xlabel('Strike Price')\n",
    "    plt.ylabel('Implied Volatility')\n",
    "    plt.title('Comparison of Interpolation Methods')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Enhanced Prediction Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enhanced_predict_iv(data):\n",
    "    data = data.copy()\n",
    "    \n",
    "    # Phase 1: Enhanced put-call parity with dynamic adjustment\n",
    "    for strike, cols in strike_dict.items():\n",
    "        call_col = cols['call']\n",
    "        put_col = cols['put']\n",
    "        \n",
    "        if call_col in data.columns and put_col in data.columns:\n",
    "            for idx in data.index:\n",
    "                call_val = data.at[idx, call_col]\n",
    "                put_val = data.at[idx, put_col]\n",
    "                underlying = data.at[idx, 'underlying']\n",
    "                strike_price = extract_strike_price(strike)\n",
    "                \n",
    "                # Calculate theoretical put-call parity adjustment\n",
    "                moneyness = calculate_moneyness(strike_price, underlying)\n",
    "                \n",
    "                if pd.isna(call_val) and not pd.isna(put_val):\n",
    "                    # Enhanced adjustment based on moneyness and volatility level\n",
    "                    adjustment = 0.001 * (moneyness - 1.0) * (1 + put_val)\n",
    "                    data.at[idx, call_col] = max(0.01, put_val + adjustment)\n",
    "                elif pd.isna(put_val) and not pd.isna(call_val):\n",
    "                    # Enhanced adjustment based on moneyness and volatility level\n",
    "                    adjustment = 0.001 * (1.0 - moneyness) * (1 + call_val)\n",
    "                    data.at[idx, put_col] = max(0.01, call_val + adjustment)\n",
    "    \n",
    "    # Phase 2: Enhanced SVI interpolation\n",
    "    for idx, row in data.iterrows():\n",
    "        underlying = row['underlying']\n",
    "        \n",
    "        # Collect available IV values\n",
    "        available_data = []\n",
    "        for col in iv_columns:\n",
    "            if col in row and not pd.isna(row[col]):\n",
    "                strike = extract_strike_price(col.split('_')[-1])\n",
    "                available_data.append((strike, row[col], col))\n",
    "        \n",
    "        if len(available_data) >= 2:\n",
    "            strikes, ivs, cols = zip(*available_data)\n",
    "            \n",
    "            # Get missing strikes\n",
    "            missing_data = []\n",
    "            for col in iv_columns:\n",
    "                if col in data.columns and pd.isna(data.at[idx, col]):\n",
    "                    strike = extract_strike_price(col.split('_')[-1])\n",
    "                    missing_data.append((strike, col))\n",
    "            \n",
    "            if missing_data:\n",
    "                missing_strikes, missing_cols = zip(*missing_data)\n",
    "                \n",
    "                # Use enhanced SVI interpolation\n",
    "                predicted_ivs = advanced_interpolation(strikes, ivs, missing_strikes, 'enhanced_svi')\n",
    "                \n",
    "                # Apply predictions\n",
    "                for i, col in enumerate(missing_cols):\n",
    "                    data.at[idx, col] = predicted_ivs[i]\n",
    "        \n",
    "        else:\n",
    "            # Enhanced fallback using underlying price similarity\n",
    "            current_underlying = row['underlying']\n",
    "            \n",
    "            # Find similar underlying prices in training data\n",
    "            if len(available_data) == 1:\n",
    "                # Use the single available value as base\n",
    "                base_iv = available_data[0][1]\n",
    "            else:\n",
    "                # Use underlying-specific statistics or global mean\n",
    "                if current_underlying in underlying_stats:\n",
    "                    available_cols = [col for col in iv_columns if col in underlying_stats[current_underlying]]\n",
    "                    if available_cols:\n",
    "                        base_iv = np.mean([underlying_stats[current_underlying][col]['mean'] for col in available_cols])\n",
    "                    else:\n",
    "                        base_iv = overall_mean\n",
    "                else:\n",
    "                    base_iv = overall_mean\n",
    "            \n",
    "            # Apply base IV to missing values with enhanced noise\n",
    "            for col in iv_columns:\n",
    "                if col in data.columns and pd.isna(data.at[idx, col]):\n",
    "                    # Add small random variation based on column statistics\n",
    "                    if col in global_stats:\n",
    "                        noise = np.random.normal(0, global_stats[col]['std'] * 0.01)\n",
    "                        data.at[idx, col] = max(0.01, base_iv + noise)\n",
    "                    else:\n",
    "                        data.at[idx, col] = base_iv\n",
    "    \n",
    "    # Phase 3: Cross-sectional consistency enforcement\n",
    "    for idx, row in data.iterrows():\n",
    "        strike_iv_pairs = []\n",
    "        for col in iv_columns:\n",
    "            if col in data.columns and not pd.isna(data.at[idx, col]):\n",
    "                strike = extract_strike_price(col.split('_')[-1])\n",
    "                strike_iv_pairs.append((strike, data.at[idx, col]))\n",
    "        \n",
    "        if len(strike_iv_pairs) >= 3:\n",
    "            strikes, ivs = zip(*strike_iv_pairs)\n",
    "            strikes = np.array(strikes)\n",
    "            ivs = np.array(ivs)\n",
    "            \n",
    "            # Apply enhanced smoothing to maintain smile shape\n",
    "            try:\n",
    "                svi_params = fit_enhanced_svi_smile(strikes, ivs, row['underlying'])\n",
    "                if svi_params is not None:\n",
    "                    for col in iv_columns:\n",
    "                        if col in data.columns:\n",
    "                            strike = extract_strike_price(col.split('_')[-1])\n",
    "                            log_moneyness = np.log(strike / row['underlying'])\n",
    "                            smoothed_iv = enhanced_svi_parametrization(log_moneyness, *svi_params)\n",
    "                            if 0.01 < smoothed_iv < 1.0:\n",
    "                                # Blend original and smoothed (70% original, 30% smoothed)\n",
    "                                data.at[idx, col] = 0.7 * data.at[idx, col] + 0.3 * smoothed_iv\n",
    "            except:\n",
    "                pass\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Validation and Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create validation split\n",
    "train_df, val_df = train_test_split(train, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Training split size: {len(train_df)}\")\n",
    "print(f\"Validation split size: {len(val_df)}\")\n",
    "\n",
    "# Apply to validation set\n",
    "val_pred = enhanced_predict_iv(val_df)\n",
    "\n",
    "# Calculate MSE only on originally masked validation points\n",
    "mse_vals = []\n",
    "for col in iv_columns:\n",
    "    if col in val_df.columns and col in val_pred.columns:\n",
    "        # Focus only on points that were originally missing\n",
    "        mask = val_df[col].isna() & val_pred[col].notna()\n",
    "        if mask.any():\n",
    "            se = (val_df.loc[mask, col] - val_pred.loc[mask, col]) ** 2\n",
    "            mse_vals.append(se.mean())\n",
    "\n",
    "validation_mse = np.mean(mse_vals) if mse_vals else 0\n",
    "print(f\"\\nValidation MSE (masked points only): {validation_mse:.12f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. Test Prediction and Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply to test set\n",
    "test_pred = enhanced_predict_iv(test)\n",
    "\n",
    "# Prepare submission\n",
    "submission = test_pred[['timestamp'] + iv_columns].copy()\n",
    "submission.columns = sample_sub.columns\n",
    "\n",
    "# Verify no missing values\n",
    "assert submission.isna().sum().sum() == 0, \"Missing values detected\"\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "\n",
    "print(\"\\nFinal Submission Preview:\")\n",
    "display(submission.head())\n",
    "print(f\"\\nSubmission shape: {submission.shape}\")\n",
    "print(f\"Validation MSE: {validation_mse:.12f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10. Additional Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize predicted IVs for a sample test row\n",
    "sample_test_row = test_pred.iloc[0]\n",
    "sample_strikes = []\n",
    "sample_ivs = []\n",
    "\n",
    "for col in iv_columns[:20]:  # Just show first 20 for clarity\n",
    "    if col in sample_test_row:\n",
    "        strike = extract_strike_price(col.split('_')[-1])\n",
    "        sample_strikes.append(strike)\n",
    "        sample_ivs.append(sample_test_row[col])\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.scatter(sample_strikes, sample_ivs)\n",
    "plt.xlabel('Strike Price')\n",
    "plt.ylabel('Predicted Implied Volatility')\n",
    "plt.title('Sample Test Row: Predicted IVs Across Strikes')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
